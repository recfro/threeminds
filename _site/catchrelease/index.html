<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<title>CATCH AND RELEASE - I WAS OF THREE MINDS.</title>

  <!-- Edit site and author settings in `_config.yml` to make the social details your own -->

    <meta content="I WAS OF THREE MINDS." property="og:site_name">
  
    <meta content="CATCH AND RELEASE" property="og:title">
  
  
    <meta content="article" property="og:type">
  
  
    <meta content="Video, dimension variable; 2021; physical TVs." property="og:description">
  
  
    <meta content="https://recfro.github.io/catchrelease/" property="og:url">
  
  
    <meta content="2021-05-17T00:00:00+08:00" property="article:published_time">
    <meta content="https://recfro.github.io/about/" property="article:author">
  
  
    <meta content="https://recfro.github.io/assets/img/figs_CatchRelease01.jpg" property="og:image">
  
  
    
  
  
    
    <meta content="machine-learning" property="article:tag">
    
    <meta content="video" property="article:tag">
    
  

    <meta name="twitter:card" content="summary">
    <meta name="twitter:site" content="@">
    <meta name="twitter:creator" content="@recfreq">
  
    <meta name="twitter:title" content="CATCH AND RELEASE">
  
  
    <meta name="twitter:url" content="https://recfro.github.io/catchrelease/">
  
  
    <meta name="twitter:description" content="Video, dimension variable; 2021; physical TVs.">
  
  
    <meta name="twitter:image:src" content="https://recfro.github.io/assets/img/figs_CatchRelease01.jpg">
  

	<meta name="description" content="Video, dimension variable; 2021; physical TVs.">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<meta property="og:image" content="">
	<!-- Chrome, Firefox OS and Opera -->
	<meta name="theme-color" content="#263959">
	<!-- Windows Phone -->
	<meta name="msapplication-navbutton-color" content="#263959">
	<!-- iOS Safari -->
	<meta name="apple-mobile-web-app-status-bar-style" content="#263959">
	<!-- Google Fonts -->
	<link href="https://fonts.googleapis.com/css?family=PT+Serif:400,700|Lato:300,400,700&display=swap" rel="stylesheet">
	<!-- Font Awesome -->
	<link rel="stylesheet" href="/assets/fonts/font-awesome/css/font-awesome.min.css">
	<!-- Styles -->
	<link rel="stylesheet" href="/assets/css/main.css">
</head>

<body>

  <div class="wrapper">
    <aside class="sidebar">
  <header>
    <div class="about">
      <div class="cover-author-image">
        <a href="/"><img src="/assets/img/figs_threeminds09extended03.jpg" alt="I WAS OF THREE MINDS"></a>
      </div>
      <div class="author-name">I WAS OF THREE MINDS</div>
      <p>A <a href="https://vimeo.com/566114459">machine learning exhibition</a> by Studio for Narrative Spaces, curated by Zijing Song.</p>
    </div>
  </header> <!-- End Header -->
  <footer>
    <section class="contact">
      <h3 class="contact-title">Contact us</h3>
      <ul>
        
          <li class="linkedin"><a href="https://instagram.com/studiofornarrativespaces" target="_blank"><i class="fa fa-linkedin"></i></a></li>
        
        
          <li><a href="https://facebook.com/rayLCphoto" target="_blank"><i class="fa fa-facebook" aria-hidden="true"></i></a></li>
        
        
          <li class="github"><a href="http://github.com/recfro" target="_blank"><i class="fa fa-github"></i></a></li>
        
        
          <li><a href="https://twitter.com/recfreq" target="_blank"><i class="fa fa-twitter" aria-hidden="true"></i></a></li>
        
        <!-- 
          <li class="email"><a href="mailto:example.david@blog.com"><i class="fa fa-envelope-o" aria-hidden="true"></i></a></li>
         -->
      </ul>
    </section> <!-- End Section Contact -->
    <div class="copyright">
      <p>2021 &copy; RAY LC</p>
    </div>
  </footer> <!-- End Footer -->
</aside> <!-- End Sidebar -->
<div class="content-box clearfix">
  <article class="article-page">
  <div class="page-content">
    
    <div class="page-cover-image">
      <figure>
        <img class="page-image" src=/assets/img/figs_CatchRelease01.jpg alt="CATCH AND RELEASE">
        
      </figure>
    </div> <!-- End Page Cover Image -->
    
    <div class="wrap-content">
      <header class="header-page">
        <h1 class="page-title">CATCH AND RELEASE</h1>
        <div class="page-date"><span>2021, May 17&nbsp;&nbsp;&nbsp;&nbsp;</span></div>
      </header>
      <p align="center">
Video, dimension variable; 2021; 4x CRT TVs.<br /><br />
"The limits of my language means the limits of my world."<br />
- Tractatus Logico-Philosophicus<br />
by Ludwig Wittgenstein<br /><br />
<iframe width="511" height="375" src="https://www.youtube.com/embed/9MgQj5L2vMg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
<img src="/assets/img/proj_iwasalwaysthere-48.jpg" />
</p>

<p>The way we imagine machines see us is imbued with our own biased perceptions and expectations, and nothing like the way machines actually see us. In this work, I use the medium of dance to show how machines can digest the dynamic forms of human bodies in different genres of music-driven movement. As we marvel at the patterns detected by computer vision, free of the human way of looking, we begin to understand how to see the world the way machines do. It isn’t until the end of the dance when we can reunite with our comfortable human visions, but by then the dance is finished, and we wondered what the dancing experience really was like, if we didn’t have to limit ourselves to the lens of the machine. Machine vision can only catch the fleeting forms of the human, and release them when they are no longer detected. They can see the dynamic patterns, but they can’t see the reality behind the abstractions. Perhaps mere abstractions are enough?</p>

<p>Catch and Release uses the Yolo algorithm to computationally detect human movements in four dance performances shown on four CRT TV’s: Cuban Rueda, Swing, Bollywood, and Salsa. See our exhibition info: <a href="/assets/img/ImAlwaysHere_Pamphlet_RAYLC_crop.pdf">LC (2021)</a>.</p>

<p align="center">
<img src="/assets/img/figs_CatchRelease01.gif" />
<img src="/assets/img/proj_iwasalwaysthere-30.jpg" />
</p>

<p>The way machines see us vs the way we see are selves are flip sides of the same coin. Take a movement-based experience like dance (choreographed by the artist and performed in New York and Tokyo venues), machines see merely patterns and movement, often detecting people where there is none, or seeing inconsequential objects that don’t contribute to our conscious experience. For example, it can see a photographer in the stands who stood up a couple of times, or an usher who arrives just at the end, or two dancers “fused” into one by the algorithm, or a distant face walking up the parking lot in the outdoor venue, etc, whereas humans have the attention to filter them out from their consciousness because they don’t contribute to the dance itself. These quirks abound in the piece itself, where each of the four performances take place in different spaces, with different musical rhythms and contexts.</p>

<p>Just by looking at the machine interpretation of the video itself, we can see patterns of activity that, if well immersed in the medium, gives us a sense of what the machine really perceives: probabilities of an object being a person, and the instantaneous prediction of her presence. The four videos conver a spectrum, including jazz swing, Cuban Rueda, a Bollywood-west coast swing medly, and salsa. When we hear the music, we begin to put the machine side and the human side together, but then our human side begins to yearn to see the real thing, the real performance behind the cloud. At the end, we see only the celebratory ending, a posthoc horay to the human attention process, in trying to see the story that doesn’t exist in the machine, and in the story that isn’t shown to the human. Often we catch the machine’s perspective for a brief moment, and then release it to become human again.</p>

<p align="center">
<img src="/assets/img/proj_iwasalwaysthere-12.jpg" />
<img src="/assets/img/proj_iwasalwaysthere-34.jpg" />
</p>

<p>The four videos are each timed exactly 2:10. They each begin only with the computer vision outputs (rectangular drawings of predicted human locations) with probabilities, and each begin revealing the original video at 1:56, before going dark for the final 10 seconds to begin the loop again. They should be shown synchronized on four CRT style TVs. The TV colors can be tuned to show the rectangles at different colors with vintage perspective. The vintage feel of the TVs and video colors make it appear an old analog system, and contrasts with the technical proficiency of the computer vision prediction. The dance forms themselves are analog experiences, and to miss them is to miss the moment forever. Each TV is attached to a head phone, allowing individuals to experience each piece separately. The TVs should also be put in proximity so that there’s a social component of seeing what others are seeing, or potentially seeing others dance to the music. Media players can be setup to loop the videos, and a common power source allows the CRT TVs and videos to be on at the same time with a single switch. The geometric arrangement of the four TVs is up to the gallery. A total of up to 7 videos (including from other performances) are available if more artifacts are desired.</p>

<p align="center">
<img src="/assets/img/proj_iwasalwaysthere-32.jpg" />
</p>

      <div class="page-footer">
        <div class="page-share">
          <a href="https://twitter.com/intent/tweet?text=CATCH AND RELEASE&url=https://recfro.github.io/catchrelease/" title="Share on Twitter" rel="nofollow" target="_blank">Twitter</a>
          <a href="https://facebook.com/sharer.php?u=https://recfro.github.io/catchrelease/" title="Share on Facebook" rel="nofollow" target="_blank">Facebook</a>
          <a href="https://plus.google.com/share?url=https://recfro.github.io/catchrelease/" title="Share on Google+" rel="nofollow" target="_blank">Google+</a>
        </div>
        <div class="page-tag">
          
            <a href="/tags#machine-learning" class="tag">&#35; machine-learning</a>
          
            <a href="/tags#video" class="tag">&#35; video</a>
          
        </div>
      </div>
      <section class="comment-area">
  <div class="comment-wrapper">
    
  </div>
</section> <!-- End Comment Area -->

    </div> <!-- End Wrap Content -->
  </div> <!-- End Page Content -->
</article> <!-- End Article Page -->

</div>

  </div>
  
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', '', 'auto');
  ga('send', 'pageview');
</script> <!-- End Analytics -->

</body>
</html>
