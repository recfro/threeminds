---
layout: post
title: LIGHT UP
date: 2022-01-20
description: Video projection, 6x2m; 2022. # (optional)
img: proj_lightup-16.jpg # (optional)
fig-caption: # (optional)
tags: [machine-learning, video, projection] # add tag
---
<p align="center">
video projection, 6x2m; 2022.<br><br>
"If you want to know how much darkness there is around you,<br>
you must sharpen your eyes, peering at the faint lights in the distance.<br>
<i>Invisible Cities</i> by Italo Calvino<br><br>
<iframe width="591" height="377" src="https://www.youtube.com/embed/Qb_-z3vdjqo/" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</p>

The city we imagine together is our collective we. When we wake, the city comes alive, and when we work, the city is illuminated by signs of activity. How do we see ourselves in this collective striving admist a city in flux? Light Up uses over 4000 photos of Hong Kong in the day and night time to generate a collective moment of the city going into darkness as lights come on, an unreal version of the city from the lens of machine learning. As we look closely from a collective perspective afforded by machine learning, we realize that the ebb and flow of a city is the ups and down of us, as we move, strive, and become enlightened. Programming by Zhiyuan Zhang.

Light Up is a Machine-Learning generated interpolated experience using StyleGANS2 (visuals) and GanSynth (music). Light Up was exhibited at the immersive exhibition Light Up at [Goethe Institute, Hong Kong Arts Centre](https://www.goethe.de/ins/hon/en/ver.cfm?event_id=23590037) curated by Zoe Chan. It was shown at Mind(e)scape at [Soho House Hong Kong](https://www.instagram.com/tv/CfndrgSlYTA/?utm_source=ig_web_copy_link) curated by Linda Cheung.

<p align="center">
<img src="{{site.baseurl}}/assets/img/proj_lightup-15.jpg">
<img src="{{site.baseurl}}/assets/img/proj_lightup-13.jpg">
</p>

<p align="center">
<img src="{{site.baseurl}}/assets/img/gifs_LightUp01.gif">
</p>

Light Up has been shown in multiple forms reflecting its diverse perspectives. For Soho House, it was a set of CRT TVs synchronized to show a double vision of the city's transition from daylight to nightlight without sound. For Hong Kong Arts Centre, sound generated from the music of Bach fed into GANSynth allowed us to create three unique musical pieces from the same midi tunes. These unique timbres generated by Machine Learning were designed to have three types of voices: sustained, plucked sounds, and symphonic sounds. When played together they appear as a symphony that uniquely changes timbre within each of its voices over time. For the Goethe Institute installation, three versions of the video that began from the same frame and interpolated through different paths were produced: one purely in the daytime, one in the nighttime, one that transitions from daytime to nighttime. These three videos are matched to the three voices of the ML-generated music, so that the symphony produced by the three versions have both visual and auditory harmony. The visual symphony comes from different ways of interpolating the city; the musical symphony comes from the timbre of the mixed voices. Indeed it is a lighting up of multiple collective perspectives as seen by machine learning.

<p align="center">
<img src="{{site.baseurl}}/assets/img/proj_lightup-17.jpg">
<img src="{{site.baseurl}}/assets/img/proj_lightup-18.jpg">
<img src="{{site.baseurl}}/assets/img/proj_lightup-12.jpg">
</p>
