---
layout: post
title: CATCH AND RELEASE
date: 2021-05-17
description: Video, dimension variable; 2021; physical TVs. # Add post description (optional)
img: figs_CatchRelease01.jpg # Add image post (optional)
tags: [machine-learning, video] # add tag
---
<p align="center">
Video, dimension variable; 2021; physical TVs.<br><br>
""<br>
- <br><br>
<img src="{{site.baseurl}}/assets/img/figs_CatchRelease01.gif">
</p>

The way we imagine machines see us is imbued with our own biased perceptions and expectations, and nothing like the way machines actually see us. In this work, I use the medium of dance to show how machines can digest the dynamic forms of human bodies in different genres of music-driven movement. As we marvel at the patterns detected by computer vision and free of the human way of looking, we begin to understand how to see the world the way machines do. It isn't until the end of the dance when we can reunite with our comfortable human visions, but by then the dance is finished, and we wondered what it really was like, if we didn't have to limit ourselves to the lens of the machine. Machine vision can only catch the fleeting forms of the human, and release them when they are no longer detected. They can see the dynamic patterns, but they can't see the reality behind the abstractions. Perhaps the mere abstractions are enough?

Catch and Release uses the Yolo algorithm to computationally detect human movements in four dance performances: Cuban Rueda, Swing, West Coast-Bollywood medley, and Salsa. For more info, see our exhibition info: [LC (2021)][show].

[show]: ..

<p align="center">
<img src="{{site.baseurl}}/assets/img/figs_CatchRelease02.jpg">
</p>
